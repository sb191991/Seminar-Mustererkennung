

@article{badshah2019deep,
  title={Deep features-based speech emotion recognition for smart affective services},
  author={Badshah, Abdul Malik and Rahim, Nasir and Ullah, Noor and Ahmad, Jamil and Muhammad, Khan and Lee, Mi Young and Kwon, Soonil and Baik, Sung Wook},
  journal={Multimedia Tools and Applications},
  volume={78},
  number={5},
  pages={5571--5589},
  year={2019},
  publisher={Springer}
}

@inproceedings{cnn,
author = {Huang, Zhengwei and Dong, Ming and Mao, Qirong and Zhan, Yongzhao},
title = {Speech Emotion Recognition Using CNN},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647868.2654984},
doi = {10.1145/2647868.2654984},
abstract = {Deep learning systems, such as Convolutional Neural Networks (CNNs), can infer a hierarchical representation of input data that facilitates categorization. In this paper, we propose to learn affect-salient features for Speech Emotion Recognition (SER) using semi-CNN. The training of semi-CNN has two stages. In the first stage, unlabeled samples are used to learn candidate features by contractive convolutional neural network with reconstruction penalization. The candidate features, in the second step, are used as the input to semi-CNN to learn affect-salient, discriminative features using a novel objective function that encourages the feature saliency, orthogonality and discrimination. Our experiment results on benchmark datasets show that our approach leads to stable and robust recognition performance in complex scenes (e.g., with speaker and environment distortion), and outperforms several well-established SER features.},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {801–804},
numpages = {4},
keywords = {computing methodologies-pattern recognition-design methodology-feature evaluation and selection, speech emotion recognition; salient feature learning},
location = {Orlando, Florida, USA},
series = {MM '14}
}

@INPROCEEDINGS{elearning,
  author={Li, Wu and Zhang, Yanhui and Fu, Yingzi},
  booktitle={Third International Conference on Natural Computation (ICNC 2007)}, 
  title={Speech Emotion Recognition in E-learning System Based on Affective Computing}, 
  year={2007},
  volume={5},
  number={},
  pages={809-813},
  doi={10.1109/ICNC.2007.677}}

@INPROCEEDINGS{spectrogram,
  author={Badshah, Abdul Malik and Ahmad, Jamil and Rahim, Nasir and Baik, Sung Wook},
  booktitle={2017 International Conference on Platform Technology and Service (PlatCon)}, 
  title={Speech Emotion Recognition from Spectrograms with Deep Convolutional Neural Network}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/PlatCon.2017.7883728}}

@article{speech_in_hci,
    author = {Clark, Leigh and Doyle, Philip and Garaialde, Diego and Gilmartin, Emer and Schlögl, Stephan and Edlund, Jens and Aylett, Matthew and Cabral, João and Munteanu, Cosmin and Edwards, Justin and R Cowan, Benjamin},
    title = "{The State of Speech in HCI: Trends, Themes and Challenges}",
    journal = {Interacting with Computers},
    volume = {31},
    number = {4},
    pages = {349-371},
    year = {2019},
    month = {09},
    abstract = "{Speech interfaces are growing in popularity. Through a review of 99 research papers this work maps the trends, themes, findings and methods of empirical research on speech interfaces in the field of human–computer interaction (HCI). We find that studies are usability/theory-focused or explore wider system experiences, evaluating Wizard of Oz, prototypes or developed systems. Measuring task and interaction was common, as was using self-report questionnaires to measure concepts like usability and user attitudes. A thematic analysis of the research found that speech HCI work focuses on nine key topics: system speech production, design insight, modality comparison, experiences with interactive voice response systems, assistive technology and accessibility, user speech production, using speech technology for development, peoples’ experiences with intelligent personal assistants and how user memory affects speech interface interaction. From these insights we identify gaps and challenges in speech research, notably taking into account technological advancements, the need to develop theories of speech interface interaction, grow critical mass in this domain, increase design work and expand research from single to multiple user interaction contexts so as to reflect current use contexts. We also highlight the need to improve measure reliability, validity and consistency, in the wild deployment and reduce barriers to building fully functional speech interfaces for research.Most papers focused on usability/theory-based or wider system experience research with a focus on Wizard of Oz and developed systemsQuestionnaires on usability and user attitudes often used but few were reliable or validatedThematic analysis showed nine primary research topicsChallenges identified in theoretical approaches and design guidelines, engaging with technological advances, multiple user and in the wild contexts, critical research mass and barriers to building speech interfaces}",
    issn = {0953-5438},
    doi = {10.1093/iwc/iwz016},
    url = {https://doi.org/10.1093/iwc/iwz016},
    eprint = {https://academic.oup.com/iwc/article-pdf/31/4/349/33525046/iwz016.pdf},
}

@article{imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@INPROCEEDINGS{bilderkennung,
  author={Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
  booktitle={2017 International Conference on Engineering and Technology (ICET)}, 
  title={Understanding of a convolutional neural network}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICEngTechnol.2017.8308186}}

@inproceedings{burkhardt2005database,
  title={A database of German emotional speech},
  author={Burkhardt, Felix and Paeschke, Astrid and Rolfes, Miriam and Sendlmeier, Walter F and Weiss, Benjamin},
  booktitle={Ninth european conference on speech communication and technology},
  year={2005}
}

@article{svm,
  title={Speech emotion recognition using support vector machine},
  author={Pan, Yixiong and Shen, Peipei and Shen, Liping},
  journal={International Journal of Smart Home},
  volume={6},
  number={2},
  pages={101--108},
  year={2012},
  publisher={Citeseer}
}

@article{HMM,
  title={Hidden markov models},
  author={Eddy, Sean R},
  journal={Current opinion in structural biology},
  volume={6},
  number={3},
  pages={361--365},
  year={1996},
  publisher={Elsevier}
}